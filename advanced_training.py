# advanced_training.py - COMPLETE ENHANCED VERSION WITH AUTOMATIC GRADUATION CALCULATION
import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Any, Optional, Set
import logging
from datetime import datetime
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from imblearn.over_sampling import SMOTE
import warnings
warnings.filterwarnings('ignore')

# Setup logger
logger = logging.getLogger(__name__)

class AdvancedFeatureEngineer:
    """
    Advanced Context-Aware Feature Engineering System
    ‚úÖ ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö Transcript Format (1 ‡∏ô‡∏±‡∏Å‡∏®‡∏∂‡∏Å‡∏©‡∏≤ = ‡∏´‡∏•‡∏≤‡∏¢‡πÅ‡∏ñ‡∏ß)
    ‚úÖ ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Å‡∏≤‡∏£‡∏à‡∏ö‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥ (‚â§4 ‡∏õ‡∏µ = ‡∏à‡∏ö‡∏ï‡∏≤‡∏°‡πÄ‡∏Å‡∏ì‡∏ë‡πå)
    ‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á Dynamic Snapshots ‡∏ï‡∏≤‡∏°‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô
    """
    
    def __init__(self, grade_mapping: Dict[str, float]):
        """Initialize with grade mapping configuration"""
        self.grade_mapping = grade_mapping
        self.course_profiles = {}
        self.student_profiles = {}
        self.global_statistics = {}
        
    def create_dynamic_snapshot_features(self, student_data: pd.DataFrame, course_profiles: Dict[str, Dict], 
                                         snapshot_point: str = 'all') -> Dict[str, float]:
        """
        ‡∏™‡∏£‡πâ‡∏≤‡∏á Dynamic Snapshot Features ‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡∏ß‡πà‡∏≤‡∏Å‡∏µ‡πà‡πÄ‡∏ó‡∏≠‡∏°‡∏Å‡πá‡∏ï‡∏≤‡∏°
        ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏ä‡∏¥‡∏á‡∏ö‡∏£‡∏¥‡∏ö‡∏ó (Context-Aware) ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ Course DNA Profiles
        
        Args:
            student_data: ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏≠‡∏á‡∏ô‡∏±‡∏Å‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡∏Ñ‡∏ô‡∏´‡∏ô‡∏∂‡πà‡∏á
            course_profiles: DNA profiles ‡∏Ç‡∏≠‡∏á‡∏ó‡∏∏‡∏Å‡∏ß‡∏¥‡∏ä‡∏≤
            snapshot_point: ‡∏à‡∏∏‡∏î‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á snapshot ('all', 'semester_X', etc.)
        
        Returns:
            Dict ‡∏Ç‡∏≠‡∏á features ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏™‡∏°‡∏≠
        """
        # ‡∏´‡∏≤‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
        grade_col = self._find_column(student_data, ['grade', '‡πÄ‡∏Å‡∏£‡∏î'])
        grade_point_col = self._find_column(student_data, ['grade_point', '‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÄ‡∏Å‡∏£‡∏î', 'gpa_point'])
        credit_col = self._find_column(student_data, ['credit', '‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Å‡∏¥‡∏ï'])
        course_col = self._find_column(student_data, ['course_code', 'course', 'subject', '‡∏£‡∏´‡∏±‡∏™‡∏ß‡∏¥‡∏ä‡∏≤'])
        semester_col = self._find_column(student_data, ['semester', '‡πÄ‡∏ó‡∏≠‡∏°', 'term'])
        academic_year_col = self._find_column(student_data, ['academic_year', '‡∏õ‡∏µ‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤', 'year'])
        
        # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô
        grades = []
        credits = []
        courses = []
        grade_letters = []
        semesters = []
        academic_years = []
        
        for _, row in student_data.iterrows():
            if pd.notna(row[grade_col]):
                # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏Å‡∏£‡∏î
                grade_point_val = row[grade_point_col] if grade_point_col and grade_point_col in row else None
                grade_val = self._convert_grade_to_numeric(row[grade_col], grade_point_val)
                
                if grade_val is not None:
                    grades.append(grade_val)
                    grade_letters.append(str(row[grade_col]).upper())
                    courses.append(str(row[course_col]) if course_col else 'UNKNOWN')
                    
                    # ‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Å‡∏¥‡∏ï
                    try:
                        credit = float(row[credit_col]) if credit_col and pd.notna(row[credit_col]) else 3
                        credits.append(credit)
                    except:
                        credits.append(3)
                    
                    # ‡πÄ‡∏ó‡∏≠‡∏°‡πÅ‡∏•‡∏∞‡∏õ‡∏µ‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤
                    if semester_col and pd.notna(row[semester_col]):
                        semesters.append(int(row[semester_col]))
                    else:
                        semesters.append(1)
                    
                    if academic_year_col and pd.notna(row[academic_year_col]):
                        academic_years.append(int(row[academic_year_col]))
                    else:
                        academic_years.append(2023)
        
        if not grades:
            return self._get_empty_dynamic_snapshot_features()
        
        # === 1. ‡∏Ñ‡∏∏‡∏ì‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏° (Overall Features) ===
        total_credits = sum(credits)
        weighted_gpa = np.average(grades, weights=credits) if credits else np.mean(grades)
        
        # === 2. ‡∏Ñ‡∏∏‡∏ì‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢ (Distribution Features) ===
        grade_counts = {
            'A_count': sum(1 for g in grades if g >= 3.5),
            'B_count': sum(1 for g in grades if 2.5 <= g < 3.5),
            'C_count': sum(1 for g in grades if 1.5 <= g < 2.5),
            'D_count': sum(1 for g in grades if 0.5 <= g < 1.5),
            'F_count': sum(1 for g in grades if g == 0),
            'W_count': sum(1 for gl in grade_letters if gl == 'W')
        }
        
        # === 3. ‡∏Ñ‡∏∏‡∏ì‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏° (Trend Features) ===
        trend_features = self._calculate_dynamic_trend_features(grades, credits, semesters, academic_years)
        
        # === 4. ‡∏Ñ‡∏∏‡∏ì‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡πÄ‡∏ä‡∏¥‡∏á‡∏ö‡∏£‡∏¥‡∏ö‡∏ó (Context-Aware Features) ===
        context_features = self._calculate_dynamic_context_aware_features(courses, grades, course_profiles)
        
        # === 5. ‡∏Ñ‡∏∏‡∏ì‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á (Risk Features) ===
        risk_features = self._calculate_dynamic_risk_features(grades, grade_letters, courses, course_profiles)
        
        # === 6. ‡∏Ñ‡∏∏‡∏ì‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡πÄ‡∏ä‡∏¥‡∏á‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö (Comparative Features) ===
        comparative_features = self._calculate_dynamic_comparative_features(courses, grades, course_profiles)
        
        # ‡∏£‡∏ß‡∏° features ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        snapshot_features = {
            # === Overall Performance ===
            'Total_Credits_so_far': total_credits,
            'GPAX_so_far': weighted_gpa,
            'GPA_simple': np.mean(grades),
            'Total_Courses': len(grades),
            'Grade_Std': np.std(grades) if len(grades) > 1 else 0,
            'Grade_Range': max(grades) - min(grades) if grades else 0,
            
            # === Grade Distribution ===
            'A_Count': grade_counts['A_count'],
            'B_Count': grade_counts['B_count'],
            'C_Count': grade_counts['C_count'],
            'D_Count': grade_counts['D_count'],
            'F_Count': grade_counts['F_count'],
            'W_Count': grade_counts['W_count'],
            
            'A_Rate': grade_counts['A_count'] / len(grades),
            'B_Rate': grade_counts['B_count'] / len(grades),
            'C_Rate': grade_counts['C_count'] / len(grades),
            'Low_Grade_Rate': (grade_counts['D_count'] + grade_counts['F_count']) / len(grades),
            'Pass_Rate': sum(1 for g in grades if g > 0) / len(grades),
            
            # === Academic Progress ===
            'Semesters_Studied': len(set(zip(academic_years, semesters))),
            'Academic_Years_Span': max(academic_years) - min(academic_years) + 1 if academic_years else 1,
            'Avg_Credits_Per_Semester': total_credits / len(set(zip(academic_years, semesters))) if academic_years else total_credits,
            
            # === Performance Consistency ===
            'Consistency_Score': 1 / (1 + np.std(grades)) if len(grades) > 1 else 1,
            'Improvement_Trend': trend_features.get('improvement_trend', 0),
            'Recent_Performance': trend_features.get('recent_performance', weighted_gpa),
            
            # === Context-Aware Features ===
            **context_features,
            
            # === Risk Indicators ===
            **risk_features,
            
            # === Comparative Analysis ===
            **comparative_features
        }
        
        return snapshot_features
    
    def _calculate_dynamic_trend_features(self, grades: List[float], credits: List[float], 
                                         semesters: List[int], academic_years: List[int]) -> Dict[str, float]:
        """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏∏‡∏ì‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡πÅ‡∏ö‡∏ö‡πÑ‡∏î‡∏ô‡∏≤‡∏°‡∏¥‡∏Å"""
        if len(grades) < 2:
            return {
                'improvement_trend': 0,
                'recent_performance': np.mean(grades) if grades else 0,
                'gpa_volatility': 0,
                'last_semester_gpa': np.mean(grades) if grades else 0,
                'semester_performance_trend': 0
            }
        
        # ‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ï‡∏≤‡∏°‡πÄ‡∏ó‡∏≠‡∏°
        semester_data = {}
        for i, (year, sem) in enumerate(zip(academic_years, semesters)):
            key = f"{year}_{sem}"
            if key not in semester_data:
                semester_data[key] = {'grades': [], 'credits': []}
            semester_data[key]['grades'].append(grades[i])
            semester_data[key]['credits'].append(credits[i])
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì GPA ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÄ‡∏ó‡∏≠‡∏°
        semester_gpas = []
        sorted_semesters = sorted(semester_data.keys())
        
        for sem_key in sorted_semesters:
            sem_grades = semester_data[sem_key]['grades']
            sem_credits = semester_data[sem_key]['credits']
            sem_gpa = np.average(sem_grades, weights=sem_credits) if sem_credits else np.mean(sem_grades)
            semester_gpas.append(sem_gpa)
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°
        if len(semester_gpas) >= 2:
            # Linear trend
            x = np.arange(len(semester_gpas))
            trend_slope = np.polyfit(x, semester_gpas, 1)[0] if len(semester_gpas) > 1 else 0
            
            # Recent vs Early performance
            recent_avg = np.mean(semester_gpas[-2:]) if len(semester_gpas) >= 2 else semester_gpas[-1]
            early_avg = np.mean(semester_gpas[:2]) if len(semester_gpas) >= 2 else semester_gpas[0]
            improvement = recent_avg - early_avg
            
            return {
                'improvement_trend': trend_slope,
                'recent_performance': recent_avg,
                'gpa_volatility': np.std(semester_gpas),
                'last_semester_gpa': semester_gpas[-1],
                'semester_performance_trend': improvement
            }
        else:
            return {
                'improvement_trend': 0,
                'recent_performance': semester_gpas[0] if semester_gpas else 0,
                'gpa_volatility': 0,
                'last_semester_gpa': semester_gpas[0] if semester_gpas else 0,
                'semester_performance_trend': 0
            }
    
    def _calculate_dynamic_context_aware_features(self, courses: List[str], grades: List[float], 
                                                 course_profiles: Dict[str, Dict]) -> Dict[str, float]:
        """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏∏‡∏ì‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡πÄ‡∏ä‡∏¥‡∏á‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡πÅ‡∏ö‡∏ö‡πÑ‡∏î‡∏ô‡∏≤‡∏°‡∏¥‡∏Å ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ Course DNA Profiles"""
        
        context_features = {
            'Avg_Course_Difficulty': 0,
            'Performance_vs_Course_Avg': 0,
            'Killer_Courses_Taken': 0,
            'Killer_Courses_Passed': 0,
            'Easy_Courses_Taken': 0,
            'GPA_Booster_Courses': 0,
            'Above_Course_Avg_Count': 0,
            'Below_Course_Avg_Count': 0,
            'Excellence_in_Hard_Courses': 0,
            'Struggle_in_Easy_Courses': 0,
            'Competitive_Courses_Performance': 0,
            'Grade_Inflation_Benefit': 0
        }
        
        if not course_profiles or not courses:
            return context_features
        
        # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ß‡∏¥‡∏ä‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏ô
        course_difficulties = []
        performance_vs_avg = []
        killer_taken = 0
        killer_passed = 0
        easy_taken = 0
        gpa_booster_taken = 0
        above_avg = 0
        below_avg = 0
        excellence_hard = 0
        struggle_easy = 0
        competitive_performance = []
        inflation_benefit = 0
        
        for course, grade in zip(courses, grades):
            if course in course_profiles:
                profile = course_profiles[course]
                
                # ‡πÄ‡∏Å‡πá‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏Å‡∏Ç‡∏≠‡∏á‡∏ß‡∏¥‡∏ä‡∏≤
                course_difficulties.append(profile['difficulty_score'])
                
                # ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏Ç‡∏≠‡∏á‡∏ß‡∏¥‡∏ä‡∏≤
                grade_diff = grade - profile['avg_grade']
                performance_vs_avg.append(grade_diff)
                
                if grade_diff > 0:
                    above_avg += 1
                else:
                    below_avg += 1
                
                # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ß‡∏¥‡∏ä‡∏≤
                if profile['is_killer_course']:
                    killer_taken += 1
                    if grade > 0:  # ‡∏ú‡πà‡∏≤‡∏ô
                        killer_passed += 1
                    if grade >= profile['excellence_threshold']:
                        excellence_hard += 1
                
                if profile['is_easy_course']:
                    easy_taken += 1
                    if grade < profile['struggle_threshold']:
                        struggle_easy += 1
                
                if profile['is_gpa_booster']:
                    gpa_booster_taken += 1
                
                # Competitive performance
                competitive_performance.append(grade * profile['competitive_index'])
                
                # Grade inflation benefit
                if profile['grade_inflation'] and grade >= 3.0:
                    inflation_benefit += 1
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢
        total_courses = len(courses)
        if total_courses > 0:
            context_features.update({
                'Avg_Course_Difficulty': np.mean(course_difficulties) if course_difficulties else 0,
                'Performance_vs_Course_Avg': np.mean(performance_vs_avg) if performance_vs_avg else 0,
                'Killer_Courses_Taken': killer_taken,
                'Killer_Courses_Passed': killer_passed,
                'Killer_Course_Pass_Rate': killer_passed / killer_taken if killer_taken > 0 else 0,
                'Easy_Courses_Taken': easy_taken,
                'GPA_Booster_Courses': gpa_booster_taken,
                'Above_Course_Avg_Count': above_avg,
                'Below_Course_Avg_Count': below_avg,
                'Above_Avg_Rate': above_avg / total_courses,
                'Excellence_in_Hard_Courses': excellence_hard,
                'Struggle_in_Easy_Courses': struggle_easy,
                'Competitive_Courses_Performance': np.mean(competitive_performance) if competitive_performance else 0,
                'Grade_Inflation_Benefit': inflation_benefit
            })
        
        return context_features
    
    def _calculate_dynamic_risk_features(self, grades: List[float], grade_letters: List[str], 
                                        courses: List[str], course_profiles: Dict[str, Dict]) -> Dict[str, float]:
        """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏∏‡∏ì‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡πÅ‡∏ö‡∏ö‡πÑ‡∏î‡∏ô‡∏≤‡∏°‡∏¥‡∏Å"""
        
        risk_features = {
            'Consecutive_Low_Grades': 0,
            'Recent_Decline_Signal': 0,
            'High_Risk_Course_Failures': 0,
            'Withdrawal_Pattern': 0,
            'Academic_Probation_Risk': 0,
            'Course_Load_Stress': 0,
            'Foundation_Course_Weakness': 0
        }
        
        if not grades:
            return risk_features
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÄ‡∏Å‡∏£‡∏î‡∏ï‡πà‡∏≥‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ô
        consecutive_low = 0
        max_consecutive_low = 0
        for grade in grades:
            if grade < 2.0:  # ‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤ C
                consecutive_low += 1
                max_consecutive_low = max(max_consecutive_low, consecutive_low)
            else:
                consecutive_low = 0
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏•‡∏î‡∏•‡∏á‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
        recent_decline = 0
        if len(grades) >= 4:
            recent_avg = np.mean(grades[-2:])
            earlier_avg = np.mean(grades[-4:-2])
            if recent_avg < earlier_avg - 0.5:
                recent_decline = 1
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏Å‡πÉ‡∏ô‡∏ß‡∏¥‡∏ä‡∏≤‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏™‡∏π‡∏á
        high_risk_failures = 0
        foundation_weakness = 0
        
        for course, grade, grade_letter in zip(courses, grades, grade_letters):
            if course in course_profiles:
                profile = course_profiles[course]
                
                # ‡∏ß‡∏¥‡∏ä‡∏≤‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏™‡∏π‡∏á
                if profile['risk_level'] == 'high_risk' and grade == 0:
                    high_risk_failures += 1
                
                # ‡∏ß‡∏¥‡∏ä‡∏≤‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô (‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡∏¥‡∏ä‡∏≤‡∏ó‡∏µ‡πà‡∏°‡∏µ course code ‡∏Ç‡∏∂‡πâ‡∏ô‡∏ï‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢ 0)
                if course.startswith('0') and grade < 2.0:
                    foundation_weakness += 1
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö pattern ‡∏Å‡∏≤‡∏£‡∏ñ‡∏≠‡∏ô
        w_count = sum(1 for gl in grade_letters if gl == 'W')
        withdrawal_pattern = 1 if w_count >= 2 else 0
        
        # ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á Academic Probation (GPA < 2.0)
        current_gpa = np.mean(grades)
        probation_risk = 1 if current_gpa < 2.0 else 0
        
        risk_features.update({
            'Consecutive_Low_Grades': max_consecutive_low,
            'Recent_Decline_Signal': recent_decline,
            'High_Risk_Course_Failures': high_risk_failures,
            'Withdrawal_Pattern': withdrawal_pattern,
            'Academic_Probation_Risk': probation_risk,
            'Foundation_Course_Weakness': foundation_weakness,
            'Overall_Risk_Score': (max_consecutive_low * 0.2 + recent_decline * 0.3 + 
                                 high_risk_failures * 0.2 + withdrawal_pattern * 0.15 + 
                                 probation_risk * 0.15)
        })
        
        return risk_features
    
    def _calculate_dynamic_comparative_features(self, courses: List[str], grades: List[float], 
                                              course_profiles: Dict[str, Dict]) -> Dict[str, float]:
        """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏∏‡∏ì‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡πÄ‡∏ä‡∏¥‡∏á‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÅ‡∏ö‡∏ö‡πÑ‡∏î‡∏ô‡∏≤‡∏°‡∏¥‡∏Å"""
        
        comparative_features = {
            'Relative_Performance_Score': 0,
            'Percentile_Performance': 0,
            'Difficulty_Adjusted_GPA': 0,
            'Competitive_Advantage': 0,
            'Course_Selection_Strategy': 0
        }
        
        if not course_profiles or not courses:
            return comparative_features
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì performance ‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö percentile ‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ß‡∏¥‡∏ä‡∏≤
        percentile_scores = []
        difficulty_weights = []
        competitive_scores = []
        
        for course, grade in zip(courses, grades):
            if course in course_profiles:
                profile = course_profiles[course]
                
                # ‡∏´‡∏≤ percentile ‡∏Ç‡∏≠‡∏á‡πÄ‡∏Å‡∏£‡∏î‡∏ô‡∏µ‡πâ‡πÉ‡∏ô‡∏ß‡∏¥‡∏ä‡∏≤‡∏ô‡∏µ‡πâ
                if grade >= profile['percentile_90']:
                    percentile_score = 0.95
                elif grade >= profile['percentile_75']:
                    percentile_score = 0.80
                elif grade >= profile['percentile_50']:
                    percentile_score = 0.60
                elif grade >= profile['percentile_25']:
                    percentile_score = 0.30
                else:
                    percentile_score = 0.10
                
                percentile_scores.append(percentile_score)
                difficulty_weights.append(profile['difficulty_score'])
                
                # Competitive score
                competitive_score = grade * (1 + profile['competitive_index'])
                competitive_scores.append(competitive_score)
        
        if percentile_scores:
            # Relative Performance Score
            relative_performance = np.mean(percentile_scores)
            
            # Difficulty-Adjusted GPA
            if difficulty_weights and len(difficulty_weights) == len(grades):
                difficulty_adjusted_gpa = np.average(grades, weights=difficulty_weights)
            else:
                difficulty_adjusted_gpa = np.mean(grades)
            
            # Competitive Advantage
            competitive_advantage = np.mean(competitive_scores) if competitive_scores else 0
            
            # Course Selection Strategy (‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ß‡∏¥‡∏ä‡∏≤‡∏á‡πà‡∏≤‡∏¢‡∏´‡∏£‡∏∑‡∏≠‡∏¢‡∏≤‡∏Å)
            avg_difficulty = np.mean(difficulty_weights) if difficulty_weights else 0.5
            if avg_difficulty > 0.7:
                strategy_score = 1  # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ß‡∏¥‡∏ä‡∏≤‡∏¢‡∏≤‡∏Å = ‡∏Å‡∏•‡πâ‡∏≤‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á
            elif avg_difficulty < 0.3:
                strategy_score = -1  # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ß‡∏¥‡∏ä‡∏≤‡∏á‡πà‡∏≤‡∏¢ = ‡πÄ‡∏•‡πà‡∏ô‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢
            else:
                strategy_score = 0  # ‡∏™‡∏°‡∏î‡∏∏‡∏•
            
            comparative_features.update({
                'Relative_Performance_Score': relative_performance,
                'Percentile_Performance': relative_performance * 100,
                'Difficulty_Adjusted_GPA': difficulty_adjusted_gpa,
                'Competitive_Advantage': competitive_advantage,
                'Course_Selection_Strategy': strategy_score
            })
        
        return comparative_features
    
    def _get_empty_dynamic_snapshot_features(self) -> Dict[str, float]:
        """‡∏™‡∏£‡πâ‡∏≤‡∏á dynamic snapshot features ‡πÄ‡∏õ‡∏•‡πà‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏£‡∏ì‡∏µ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"""
        return {
            # Overall Performance
            'Total_Credits_so_far': 0,
            'GPAX_so_far': 0,
            'GPA_simple': 0,
            'Total_Courses': 0,
            'Grade_Std': 0,
            'Grade_Range': 0,
            
            # Grade Distribution
            'A_Count': 0, 'B_Count': 0, 'C_Count': 0, 'D_Count': 0, 'F_Count': 0, 'W_Count': 0,
            'A_Rate': 0, 'B_Rate': 0, 'C_Rate': 0, 'Low_Grade_Rate': 0, 'Pass_Rate': 0,
            
            # Academic Progress
            'Semesters_Studied': 0,
            'Academic_Years_Span': 0,
            'Avg_Credits_Per_Semester': 0,
            
            # Performance Consistency
            'Consistency_Score': 0,
            'Improvement_Trend': 0,
            'Recent_Performance': 0,
            
            # Context-Aware Features
            'Avg_Course_Difficulty': 0,
            'Performance_vs_Course_Avg': 0,
            'Killer_Courses_Taken': 0,
            'Killer_Courses_Passed': 0,
            'Killer_Course_Pass_Rate': 0,
            'Easy_Courses_Taken': 0,
            'GPA_Booster_Courses': 0,
            'Above_Course_Avg_Count': 0,
            'Below_Course_Avg_Count': 0,
            'Above_Avg_Rate': 0,
            'Excellence_in_Hard_Courses': 0,
            'Struggle_in_Easy_Courses': 0,
            'Competitive_Courses_Performance': 0,
            'Grade_Inflation_Benefit': 0,
            
            # Risk Features
            'Consecutive_Low_Grades': 0,
            'Recent_Decline_Signal': 0,
            'High_Risk_Course_Failures': 0,
            'Withdrawal_Pattern': 0,
            'Academic_Probation_Risk': 0,
            'Foundation_Course_Weakness': 0,
            'Overall_Risk_Score': 0,
            
            # Comparative Features
            'Relative_Performance_Score': 0,
            'Percentile_Performance': 0,
            'Difficulty_Adjusted_GPA': 0,
            'Competitive_Advantage': 0,
            'Course_Selection_Strategy': 0
        }

    def prepare_training_data(self, df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.Series]:
        """
        Main method: ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÅ‡∏ö‡∏ö Advanced Context-Aware
        ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö Transcript Format ‡∏ó‡∏µ‡πà 1 ‡∏ô‡∏±‡∏Å‡∏®‡∏∂‡∏Å‡∏©‡∏≤ = ‡∏´‡∏•‡∏≤‡∏¢‡πÅ‡∏ñ‡∏ß
        """
        logger.info("üöÄ Starting Advanced Context-Aware Feature Engineering...")
        logger.info(f"üìä Input data shape: {df.shape}")
        
        try:
            # Step 1: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
            df = self._clean_data(df)
            
            # Step 2: ‡∏™‡∏£‡πâ‡∏≤‡∏á Course DNA Profiles ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
            logger.info("üß¨ Creating Course DNA profiles...")
            self.course_profiles = self._create_course_dna_profiles(df)
            logger.info(f"‚úÖ Created DNA profiles for {len(self.course_profiles)} courses")
            
            # Step 3: ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Transcript ‡πÄ‡∏õ‡πá‡∏ô Student Records ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Å‡∏≤‡∏£‡∏à‡∏ö‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
            logger.info("üë• Transforming transcript data to student records...")
            student_records = self._transform_transcript_to_students(df)
            logger.info(f"‚úÖ Processed {len(student_records)} unique students")
            
            # Step 4: ‡∏™‡∏£‡πâ‡∏≤‡∏á Dynamic Snapshots ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ô‡∏±‡∏Å‡∏®‡∏∂‡∏Å‡∏©‡∏≤
            logger.info("üì∏ Creating dynamic temporal snapshots...")
            all_snapshots = []
            
            for student_id, student_record in student_records.items():
                snapshots = self._create_temporal_snapshots(student_id, student_record)
                all_snapshots.extend(snapshots)
            
            logger.info(f"‚úÖ Created {len(all_snapshots)} training snapshots")
            
            if not all_snapshots:
                raise ValueError("No snapshots created! Check your data format.")
            
            # Step 5: Generate Advanced Features
            logger.info("üîß Generating advanced contextual features...")
            X = pd.DataFrame(all_snapshots)
            X = self._generate_advanced_features(X)
            
            # Step 6: Extract target variable
            if 'graduated' not in X.columns:
                raise ValueError("No 'graduated' column found in features!")
                
            y = X['graduated'].astype(int)
            
            # Log class distribution
            unique_classes, class_counts = np.unique(y, return_counts=True)
            logger.info(f"üìä Target distribution: {dict(zip(unique_classes, class_counts))}")
            
            # Remove non-feature columns
            X = X.drop(columns=['graduated', 'student_id', 'snapshot_id'], errors='ignore')
            
            # Step 7: Feature selection and normalization
            X = self._select_and_normalize_features(X)
            
            logger.info(f"‚úÖ Feature engineering completed!")
            logger.info(f"üìä Final shape: X={X.shape}, y={y.shape}")
            logger.info(f"üìä Features created: {list(X.columns)[:20]}...")  # Show first 20 features
            
            return X, y
            
        except Exception as e:
            logger.error(f"‚ùå Error in feature engineering: {e}")
            import traceback
            logger.error(traceback.format_exc())
            raise
    
    def _clean_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"""
        # Remove empty rows
        df = df.dropna(how='all')
        
        # Standardize column names
        df.columns = [col.strip().lower() for col in df.columns]
        
        # Handle special characters in column names
        df.columns = [col.replace(' ', '_').replace('-', '_') for col in df.columns]
        
        return df
    
    def _create_course_dna_profiles(self, df: pd.DataFrame) -> Dict[str, Dict]:
        """
        ‡∏™‡∏£‡πâ‡∏≤‡∏á DNA Profile ‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ß‡∏¥‡∏ä‡∏≤‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏Å-‡∏á‡πà‡∏≤‡∏¢, ‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Å‡∏≤‡∏£‡∏ï‡∏Å, ‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡πÄ‡∏Å‡∏£‡∏î
        ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏ä‡∏¥‡∏á‡∏ö‡∏£‡∏¥‡∏ö‡∏ó (Context-Aware) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö
        """
        course_profiles = {}
        
        # ‡∏´‡∏≤‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á
        course_col = self._find_column(df, ['course_code', 'course', 'subject', '‡∏£‡∏´‡∏±‡∏™‡∏ß‡∏¥‡∏ä‡∏≤'])
        grade_col = self._find_column(df, ['grade', '‡πÄ‡∏Å‡∏£‡∏î'])
        grade_point_col = self._find_column(df, ['grade_point', '‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÄ‡∏Å‡∏£‡∏î', 'gpa_point'])
        credit_col = self._find_column(df, ['credit', '‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Å‡∏¥‡∏ï'])
        
        if not course_col or not grade_col:
            logger.warning("Cannot find course or grade columns for DNA profiling")
            return {}
        
        # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ß‡∏¥‡∏ä‡∏≤
        unique_courses = df[course_col].dropna().unique()
        logger.info(f"üß¨ Analyzing {len(unique_courses)} unique courses for DNA profiling...")
        
        for course in unique_courses:
            course_data = df[df[course_col] == course]
            
            if len(course_data) < 3:  # ‡∏•‡∏î‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô
                continue
            
            # ‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏Å‡∏£‡∏î‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏Ç‡∏≠‡∏á‡∏ß‡∏¥‡∏ä‡∏≤‡∏ô‡∏µ‡πâ
            grades = []
            grade_letters = []
            credits = []
            
            for _, row in course_data.iterrows():
                if pd.notna(row[grade_col]):
                    # ‡∏™‡πà‡∏á grade_point ‡∏î‡πâ‡∏ß‡∏¢‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
                    grade_point_val = row[grade_point_col] if grade_point_col and grade_point_col in row else None
                    grade_val = self._convert_grade_to_numeric(row[grade_col], grade_point_val)
                    if grade_val is not None:
                        grades.append(grade_val)
                        grade_letters.append(str(row[grade_col]).upper())
                        
                        # ‡πÄ‡∏Å‡πá‡∏ö‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Å‡∏¥‡∏ï
                        if credit_col and credit_col in row.index:
                            try:
                                credit = float(row[credit_col])
                                credits.append(credit)
                            except:
                                credits.append(3)  # default
                        else:
                            credits.append(3)  # default
            
            if len(grades) < 3:
                continue
            
            # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì DNA ‡∏Ç‡∏≠‡∏á‡∏ß‡∏¥‡∏ä‡∏≤‡πÅ‡∏ö‡∏ö Context-Aware
            profile = {
                'course_id': str(course),
                'sample_size': len(grades),
                'avg_credit': np.mean(credits) if credits else 3,
                
                # === Core Statistics ===
                'avg_grade': np.mean(grades),
                'median_grade': np.median(grades),
                'std_grade': np.std(grades) if len(grades) > 1 else 0,
                'min_grade': np.min(grades),
                'max_grade': np.max(grades),
                
                # === Performance Distribution ===
                'fail_rate': sum(1 for g in grades if g == 0) / len(grades),
                'withdraw_rate': sum(1 for g in grade_letters if g == 'W') / len(grade_letters),
                'a_rate': sum(1 for g in grades if g >= 3.5) / len(grades),
                'b_plus_rate': sum(1 for g in grades if 3.0 <= g < 3.5) / len(grades),
                'b_rate': sum(1 for g in grades if 2.5 <= g < 3.0) / len(grades),
                'c_plus_rate': sum(1 for g in grades if 2.0 <= g < 2.5) / len(grades),
                'c_rate': sum(1 for g in grades if 1.5 <= g < 2.0) / len(grades),
                'low_grade_rate': sum(1 for g in grades if 0 < g < 2.0) / len(grades),
                'pass_rate': sum(1 for g in grades if g > 0) / len(grades),
                
                # === Difficulty Indicators ===
                'difficulty_score': self._calculate_difficulty_score(grades, grade_letters),
                'is_killer_course': sum(1 for g in grades if g == 0) / len(grades) > 0.25,
                'is_easy_course': np.mean(grades) > 3.0 and sum(1 for g in grades if g >= 3.5) / len(grades) > 0.4,
                'is_gpa_booster': np.mean(grades) > 3.2 and np.std(grades) < 0.6,
                'is_inconsistent': np.std(grades) > 1.2,
                
                # === Percentiles for Comparison ===
                'percentile_10': np.percentile(grades, 10),
                'percentile_25': np.percentile(grades, 25),
                'percentile_50': np.percentile(grades, 50),
                'percentile_75': np.percentile(grades, 75),
                'percentile_90': np.percentile(grades, 90),
                
                # === Advanced Context Features ===
                'excellence_threshold': np.percentile(grades, 80),  # ‡πÄ‡∏Å‡∏£‡∏î‡∏ó‡∏µ‡πà‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡∏î‡∏µ‡πÉ‡∏ô‡∏ß‡∏¥‡∏ä‡∏≤‡∏ô‡∏µ‡πâ
                'struggle_threshold': np.percentile(grades, 20),   # ‡πÄ‡∏Å‡∏£‡∏î‡∏ó‡∏µ‡πà‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡πÅ‡∏¢‡πà‡πÉ‡∏ô‡∏ß‡∏¥‡∏ä‡∏≤‡∏ô‡∏µ‡πâ
                'competitive_index': self._calculate_competitive_index(grades),
                'grade_inflation': 1 if np.mean(grades) > 3.0 and sum(1 for g in grades if g >= 3.5) / len(grades) > 0.5 else 0,
                
                # === Classification ===
                'course_type': self._classify_course_type(grades, grade_letters),
                'difficulty_level': self._classify_difficulty_level(grades, grade_letters),
                'risk_level': self._calculate_risk_level(grades, grade_letters),
                
                # === Contextual Insights ===
                'typical_grade': self._find_typical_grade(grades),
                'grade_distribution': self._create_grade_distribution(grades),
                'success_rate': sum(1 for g in grades if g >= 2.0) / len(grades),  # C ‡∏´‡∏£‡∏∑‡∏≠‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤
                
                # === Comparative Metrics ===
                'relative_difficulty': 0,  # ‡∏à‡∏∞‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ó‡∏∏‡∏Å‡∏ß‡∏¥‡∏ä‡∏≤‡πÅ‡∏•‡πâ‡∏ß
                'percentile_rank': 0       # ‡∏à‡∏∞‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ó‡∏∏‡∏Å‡∏ß‡∏¥‡∏ä‡∏≤‡πÅ‡∏•‡πâ‡∏ß
            }
            
            course_profiles[str(course)] = profile
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Relative Difficulty ‡πÅ‡∏•‡∏∞ Percentile Rank
        if course_profiles:
            self._calculate_relative_metrics(course_profiles)
        
        logger.info(f"‚úÖ Created DNA profiles for {len(course_profiles)} courses")
        
        # ‡∏™‡∏£‡∏∏‡∏õ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥ Course DNA
        self._summarize_course_dna_stats(course_profiles)
        
        return course_profiles
    
    def _calculate_competitive_index(self, grades: List[float]) -> float:
        """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏î‡∏±‡∏ä‡∏ô‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏Ç‡πà‡∏á‡∏Ç‡∏±‡∏ô (0-1) ‡∏¢‡∏¥‡πà‡∏á‡∏™‡∏π‡∏á‡∏¢‡∏¥‡πà‡∏á‡πÅ‡∏Ç‡πà‡∏á‡∏Ç‡∏±‡∏ô‡∏´‡∏ô‡∏±‡∏Å"""
        if not grades or len(grades) < 3:
            return 0.5
        
        # ‡∏î‡∏π‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡πÄ‡∏Å‡∏£‡∏î ‡∏ñ‡πâ‡∏≤‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏°‡∏≤‡∏Å = ‡πÅ‡∏Ç‡πà‡∏á‡∏Ç‡∏±‡∏ô‡∏´‡∏ô‡∏±‡∏Å
        std_grade = np.std(grades)
        fail_rate = sum(1 for g in grades if g == 0) / len(grades)
        high_grade_rate = sum(1 for g in grades if g >= 3.5) / len(grades)
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏î‡∏±‡∏ä‡∏ô‡∏µ
        competitive_score = (
            std_grade * 0.4 +           # ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏õ‡∏£‡∏õ‡∏£‡∏ß‡∏ô‡∏™‡∏π‡∏á = ‡πÅ‡∏Ç‡πà‡∏á‡∏Ç‡∏±‡∏ô‡∏´‡∏ô‡∏±‡∏Å
            fail_rate * 0.3 +           # ‡∏Ñ‡∏ô‡∏ï‡∏Å‡πÄ‡∏¢‡∏≠‡∏∞ = ‡πÅ‡∏Ç‡πà‡∏á‡∏Ç‡∏±‡∏ô‡∏´‡∏ô‡∏±‡∏Å
            (1 - high_grade_rate) * 0.3 # ‡∏Ñ‡∏ô‡πÑ‡∏î‡πâ‡πÄ‡∏Å‡∏£‡∏î‡∏™‡∏π‡∏á‡∏ô‡πâ‡∏≠‡∏¢ = ‡πÅ‡∏Ç‡πà‡∏á‡∏Ç‡∏±‡∏ô‡∏´‡∏ô‡∏±‡∏Å
        )
        
        return min(1.0, max(0.0, competitive_score))
    
    def _classify_difficulty_level(self, grades: List[float], grade_letters: List[str]) -> str:
        """‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏Å‡∏Ç‡∏≠‡∏á‡∏ß‡∏¥‡∏ä‡∏≤"""
        if not grades:
            return 'unknown'
        
        avg_grade = np.mean(grades)
        fail_rate = sum(1 for g in grades if g == 0) / len(grades)
        a_rate = sum(1 for g in grades if g >= 3.5) / len(grades)
        
        if fail_rate > 0.3:
            return 'very_hard'
        elif fail_rate > 0.15 and avg_grade < 2.5:
            return 'hard'
        elif avg_grade > 3.2 and a_rate > 0.4:
            return 'easy'
        elif avg_grade > 2.8 and fail_rate < 0.05:
            return 'moderate_easy'
        else:
            return 'moderate'
    
    def _calculate_risk_level(self, grades: List[float], grade_letters: List[str]) -> str:
        """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏Ç‡∏≠‡∏á‡∏ß‡∏¥‡∏ä‡∏≤"""
        if not grades:
            return 'unknown'
        
        fail_rate = sum(1 for g in grades if g == 0) / len(grades)
        withdraw_rate = sum(1 for g in grade_letters if g == 'W') / len(grade_letters)
        low_grade_rate = sum(1 for g in grades if 0 < g < 2.0) / len(grades)
        
        total_risk = fail_rate + withdraw_rate + low_grade_rate * 0.5
        
        if total_risk > 0.4:
            return 'high_risk'
        elif total_risk > 0.2:
            return 'medium_risk'
        else:
            return 'low_risk'
    
    def _find_typical_grade(self, grades: List[float]) -> float:
        """‡∏´‡∏≤‡πÄ‡∏Å‡∏£‡∏î‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ö‡πà‡∏≠‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (mode) ‡∏´‡∏£‡∏∑‡∏≠ median"""
        if not grades:
            return 0
        
        # ‡∏õ‡∏±‡∏î‡πÄ‡∏Å‡∏£‡∏î‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏®‡∏ô‡∏¥‡∏¢‡∏° 1 ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á ‡πÅ‡∏•‡πâ‡∏ß‡∏´‡∏≤ mode
        rounded_grades = [round(g * 2) / 2 for g in grades]  # ‡∏õ‡∏±‡∏î‡πÄ‡∏õ‡πá‡∏ô 0.5
        
        from collections import Counter
        grade_counts = Counter(rounded_grades)
        most_common = grade_counts.most_common(1)
        
        if most_common:
            return most_common[0][0]
        else:
            return np.median(grades)
    
    def _create_grade_distribution(self, grades: List[float]) -> Dict[str, float]:
        """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡πÄ‡∏Å‡∏£‡∏î‡πÅ‡∏ö‡∏ö‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î"""
        if not grades:
            return {}
        
        total = len(grades)
        return {
            'A_rate': sum(1 for g in grades if g >= 3.5) / total,
            'B_rate': sum(1 for g in grades if 2.5 <= g < 3.5) / total,
            'C_rate': sum(1 for g in grades if 1.5 <= g < 2.5) / total,
            'D_rate': sum(1 for g in grades if 0.5 <= g < 1.5) / total,
            'F_rate': sum(1 for g in grades if g == 0) / total
        }
    
    def _calculate_relative_metrics(self, course_profiles: Dict[str, Dict]):
        """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì metrics ‡πÄ‡∏ä‡∏¥‡∏á‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏ß‡∏¥‡∏ä‡∏≤"""
        if not course_profiles:
            return
        
        # ‡πÄ‡∏Å‡πá‡∏ö‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏Ç‡∏≠‡∏á‡∏ó‡∏∏‡∏Å‡∏ß‡∏¥‡∏ä‡∏≤
        all_avg_grades = [profile['avg_grade'] for profile in course_profiles.values()]
        all_difficulty_scores = [profile['difficulty_score'] for profile in course_profiles.values()]
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì percentile rank ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ß‡∏¥‡∏ä‡∏≤
        for course_id, profile in course_profiles.items():
            # Relative difficulty (‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö‡∏ß‡∏¥‡∏ä‡∏≤‡∏≠‡∏∑‡πà‡∏ô)
            easier_courses = sum(1 for avg in all_avg_grades if avg > profile['avg_grade'])
            profile['relative_difficulty'] = easier_courses / len(all_avg_grades)
            
            # Percentile rank ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏Å
            harder_courses = sum(1 for diff in all_difficulty_scores if diff > profile['difficulty_score'])
            profile['percentile_rank'] = harder_courses / len(all_difficulty_scores)
    
    def _summarize_course_dna_stats(self, course_profiles: Dict[str, Dict]):
        """‡∏™‡∏£‡∏∏‡∏õ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥ Course DNA"""
        if not course_profiles:
            return
        
        total_courses = len(course_profiles)
        killer_courses = sum(1 for p in course_profiles.values() if p['is_killer_course'])
        easy_courses = sum(1 for p in course_profiles.values() if p['is_easy_course'])
        gpa_boosters = sum(1 for p in course_profiles.values() if p['is_gpa_booster'])
        
        avg_difficulty = np.mean([p['difficulty_score'] for p in course_profiles.values()])
        avg_fail_rate = np.mean([p['fail_rate'] for p in course_profiles.values()])
        
        logger.info(f"üìä Course DNA Summary:")
        logger.info(f"   - Total courses analyzed: {total_courses}")
        logger.info(f"   - Killer courses (>25% fail): {killer_courses} ({killer_courses/total_courses*100:.1f}%)")
        logger.info(f"   - Easy courses: {easy_courses} ({easy_courses/total_courses*100:.1f}%)")
        logger.info(f"   - GPA boosters: {gpa_boosters} ({gpa_boosters/total_courses*100:.1f}%)")
        logger.info(f"   - Average difficulty score: {avg_difficulty:.3f}")
        logger.info(f"   - Average fail rate: {avg_fail_rate*100:.1f}%")
    
    def _transform_transcript_to_students(self, df: pd.DataFrame) -> Dict[str, Dict]:
        """
        ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Transcript (‡∏´‡∏•‡∏≤‡∏¢‡πÅ‡∏ñ‡∏ß‡∏ï‡πà‡∏≠‡∏ô‡∏±‡∏Å‡∏®‡∏∂‡∏Å‡∏©‡∏≤) ‡πÄ‡∏õ‡πá‡∏ô Student Records
        ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡∏à‡∏ö‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡∏ï‡∏≤‡∏°‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏õ‡∏µ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏ô
        """
        student_records = {}
        
        # ‡∏´‡∏≤‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå Student ID - ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏´‡∏•‡∏≤‡∏¢ format
        student_col = self._find_column(df, ['dummy_studentno', 'dummy studentno', 'studentno', 'student_id', 'student', '‡∏£‡∏´‡∏±‡∏™‡∏ô‡∏±‡∏Å‡∏®‡∏∂‡∏Å‡∏©‡∏≤', 'id', 'name', '‡∏ä‡∏∑‡πà‡∏≠'])
        
        if not student_col:
            # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ student ID ‡πÉ‡∏´‡πâ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏à‡∏≤‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡∏´‡∏£‡∏∑‡∏≠ index
            logger.warning("Cannot find Student ID column, creating dummy IDs")
            df['dummy_student_id'] = [f"student_{i}" for i in range(len(df))]
            student_col = 'dummy_student_id'
        
        # Group by student - ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ NaN
        df[student_col] = df[student_col].fillna('unknown')
        df[student_col] = df[student_col].astype(str)
        unique_students = df[student_col].unique()
        
        logger.info(f"üìä Processing {len(unique_students)} students...")
        
        graduation_stats = {'graduated': 0, 'not_graduated': 0}
        
        for i, student_id in enumerate(unique_students):
            try:
                student_data = df[df[student_col] == student_id].copy()
                
                if student_data.empty:
                    continue
                
                # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏õ‡∏µ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
                years_studied = self._calculate_years_studied(student_data)
                
                # üî¥ ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡∏à‡∏ö‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
                # ‡∏à‡∏ö‡∏ï‡∏≤‡∏°‡πÄ‡∏Å‡∏ì‡∏ë‡πå = ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô ‚â§ 4 ‡∏õ‡∏µ
                # ‡πÑ‡∏°‡πà‡∏à‡∏ö‡∏ï‡∏≤‡∏°‡πÄ‡∏Å‡∏ì‡∏ë‡πå = ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô > 4 ‡∏õ‡∏µ
                graduated_status = 1 if years_studied <= 4 else 0
                
                # ‡∏ô‡∏±‡∏ö‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥
                if graduated_status == 1:
                    graduation_stats['graduated'] += 1
                else:
                    graduation_stats['not_graduated'] += 1
                
                # Log progress ‡∏ó‡∏∏‡∏Å 10 students ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡∏ä‡πâ‡∏≤
                if (i + 1) % 10 == 0:
                    logger.info(f"  Processed {i+1}/{len(unique_students)} students...")
                
                # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡πÄ‡∏ß‡∏•‡∏≤
                student_data = self._sort_by_time(student_data)
                
                student_records[str(student_id)] = {
                    'data': student_data,
                    'graduated': graduated_status,
                    'years_studied': years_studied
                }
                
            except Exception as e:
                logger.warning(f"Error processing student {student_id}: {e}")
                continue
        
        # ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•
        logger.info(f"‚úÖ Classification results:")
        logger.info(f"   - ‡∏à‡∏ö‡∏ï‡∏≤‡∏°‡πÄ‡∏Å‡∏ì‡∏ë‡πå (‚â§4 ‡∏õ‡∏µ): {graduation_stats['graduated']} ‡∏Ñ‡∏ô")
        logger.info(f"   - ‡∏à‡∏ö‡πÑ‡∏°‡πà‡∏ï‡∏≤‡∏°‡πÄ‡∏Å‡∏ì‡∏ë‡πå (>4 ‡∏õ‡∏µ): {graduation_stats['not_graduated']} ‡∏Ñ‡∏ô")
        
        return student_records
    
    def _calculate_years_studied(self, student_data: pd.DataFrame) -> int:
        """
        ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏õ‡∏µ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• transcript
        ‡πÉ‡∏ä‡πâ "‡∏õ‡∏µ‡∏ó‡∏µ‡πà‡πÄ‡∏Ç‡πâ‡∏≤" ‡πÅ‡∏•‡∏∞ "‡∏õ‡∏µ‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤" ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì
        ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏õ‡∏µ ‡∏û.‡∏®./‡∏Ñ.‡∏®. ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
        """
        # Method 1: ‡πÉ‡∏ä‡πâ "‡∏õ‡∏µ‡∏ó‡∏µ‡πà‡πÄ‡∏Ç‡πâ‡∏≤" ‡πÅ‡∏•‡∏∞ "‡∏õ‡∏µ‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤" (‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î)
        entry_year_col = self._find_column(student_data, ['‡∏õ‡∏µ‡∏ó‡∏µ‡πà‡πÄ‡∏Ç‡πâ‡∏≤', 'entry_year', 'admission_year'])
        academic_year_col = self._find_column(student_data, ['‡∏õ‡∏µ‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤', 'academic_year', 'year'])
        
        if entry_year_col and academic_year_col:
            try:
                # ‡∏î‡∏∂‡∏á‡∏õ‡∏µ‡∏ó‡∏µ‡πà‡πÄ‡∏Ç‡πâ‡∏≤ (‡∏Ñ‡∏ß‡∏£‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î)
                entry_years = student_data[entry_year_col].dropna().unique()
                if len(entry_years) > 0:
                    entry_year = int(entry_years[0])
                    
                    # ‡∏î‡∏∂‡∏á‡∏õ‡∏µ‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏ô
                    academic_years = student_data[academic_year_col].dropna().unique()
                    if len(academic_years) > 0:
                        # ‡πÅ‡∏õ‡∏•‡∏á‡∏õ‡∏µ‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç
                        year_values = []
                        for y in academic_years:
                            year_int = self._convert_year_to_int(y)
                            if year_int:
                                year_values.append(year_int)
                        
                        if year_values:
                            # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏à‡∏≤‡∏Å‡∏õ‡∏µ‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢ - ‡∏õ‡∏µ‡∏ó‡∏µ‡πà‡πÄ‡∏Ç‡πâ‡∏≤ + 1
                            last_academic_year = max(year_values)
                            entry_year_converted = self._convert_year_to_int(entry_year)
                            
                            if entry_year_converted and last_academic_year:
                                # ‡∏ñ‡πâ‡∏≤‡∏õ‡∏µ‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡πÄ‡∏õ‡πá‡∏ô ‡∏û.‡∏®. ‡πÅ‡∏•‡∏∞‡∏õ‡∏µ‡∏ó‡∏µ‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô ‡∏Ñ.‡∏®. ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ô‡∏ó‡∏≤‡∏á‡∏Å‡∏•‡∏±‡∏ö‡∏Å‡∏±‡∏ô
                                if abs(last_academic_year - entry_year_converted) > 100:
                                    # ‡πÅ‡∏õ‡∏•‡∏á‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô
                                    if last_academic_year > 2500:  # ‡∏û.‡∏®.
                                        if entry_year_converted < 2500:  # ‡∏Ñ.‡∏®.
                                            entry_year_converted += 543
                                    else:  # ‡∏Ñ.‡∏®.
                                        if entry_year_converted > 2500:  # ‡∏û.‡∏®.
                                            entry_year_converted -= 543
                                
                                years_studied = last_academic_year - entry_year_converted + 1
                                return max(1, min(10, years_studied))  # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡πÑ‡∏ß‡πâ 1-10 ‡∏õ‡∏µ
                
            except Exception as e:
                logger.debug(f"Error in Method 1: {e}")
        
        # Method 2: ‡πÉ‡∏ä‡πâ‡∏õ‡∏µ‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
        if academic_year_col:
            try:
                years = student_data[academic_year_col].dropna().unique()
                if len(years) > 0:
                    year_values = []
                    for y in years:
                        year_int = self._convert_year_to_int(y)
                        if year_int:
                            year_values.append(year_int)
                    
                    if year_values:
                        return max(year_values) - min(year_values) + 1
            except Exception as e:
                logger.debug(f"Error in Method 2: {e}")
        
        # Method 3: ‡πÉ‡∏ä‡πâ‡πÄ‡∏ó‡∏≠‡∏°/‡∏†‡∏≤‡∏Ñ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô
        term_col = self._find_column(student_data, ['term', 'semester', '‡∏†‡∏≤‡∏Ñ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô', '‡πÄ‡∏ó‡∏≠‡∏°'])
        if term_col and term_col in student_data.columns:
            try:
                # ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏ó‡∏≠‡∏°‡∏ó‡∏µ‡πà‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô
                terms = student_data[term_col].dropna().unique()
                total_terms = len(terms)
                # ‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏ß‡πà‡∏≤ 1 ‡∏õ‡∏µ = 2 ‡πÄ‡∏ó‡∏≠‡∏° (‡πÑ‡∏°‡πà‡∏ô‡∏±‡∏ö summer)
                return max(1, (total_terms + 1) // 2)
            except Exception as e:
                logger.debug(f"Error in Method 3: {e}")
        
        # Method 4: ‡∏ô‡∏±‡∏ö‡∏à‡∏≤‡∏Å‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ß‡∏¥‡∏ä‡∏≤ (fallback)
        total_courses = len(student_data)
        courses_per_year = 14  # ‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì 7 ‡∏ß‡∏¥‡∏ä‡∏≤‡∏ï‡πà‡∏≠‡πÄ‡∏ó‡∏≠‡∏° x 2 ‡πÄ‡∏ó‡∏≠‡∏°
        return max(1, min(8, (total_courses + courses_per_year - 1) // courses_per_year))
    
    def _convert_year_to_int(self, year_value) -> Optional[int]:
        """‡πÅ‡∏õ‡∏•‡∏á‡∏õ‡∏µ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö ‡∏û.‡∏®./‡∏Ñ.‡∏®."""
        if pd.isna(year_value):
            return None
        
        try:
            year_str = str(year_value).strip()
            
            # ‡∏•‡∏ö‡∏≠‡∏±‡∏Å‡∏Ç‡∏£‡∏∞‡∏û‡∏¥‡πÄ‡∏®‡∏©
            year_str = year_str.replace('/', '').replace('-', '').replace(' ', '')
            
            # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç
            year_int = int(float(year_str))
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏°‡πÄ‡∏´‡∏ï‡∏∏‡∏™‡∏°‡∏ú‡∏•
            if 1900 <= year_int <= 2100:  # ‡∏Ñ.‡∏®.
                return year_int
            elif 2400 <= year_int <= 2700:  # ‡∏û.‡∏®.
                return year_int
            else:
                return None
                
        except (ValueError, TypeError):
            return None
    
    def _sort_by_time(self, student_data: pd.DataFrame) -> pd.DataFrame:
        """‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏°‡πÄ‡∏ß‡∏•‡∏≤"""
        # Try to sort by year and term
        year_col = self._find_column(student_data, ['year', '‡∏õ‡∏µ', '‡∏õ‡∏µ‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤'])
        term_col = self._find_column(student_data, ['term', 'semester', '‡πÄ‡∏ó‡∏≠‡∏°'])
        
        if year_col and term_col:
            try:
                return student_data.sort_values([year_col, term_col])
            except:
                pass
        elif year_col:
            try:
                return student_data.sort_values(year_col)
            except:
                pass
        
        return student_data
    
    def _create_temporal_snapshots(self, student_id: str, student_record: Dict) -> List[Dict]:
        """
        ‡∏™‡∏£‡πâ‡∏≤‡∏á Dynamic Snapshots ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ô‡∏±‡∏Å‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏ô
        ‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ì‡πå‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤ (‡πÄ‡∏ó‡∏≠‡∏°) ‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô
        """
        snapshots = []
        student_data = student_record['data']
        graduated = student_record['graduated']
        
        # ‡∏´‡∏≤‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ
        course_col = self._find_column(student_data, ['course_code', 'course', 'subject', '‡∏£‡∏´‡∏±‡∏™‡∏ß‡∏¥‡∏ä‡∏≤'])
        grade_col = self._find_column(student_data, ['grade', '‡πÄ‡∏Å‡∏£‡∏î'])
        credit_col = self._find_column(student_data, ['credit', '‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Å‡∏¥‡∏ï'])
        year_col = self._find_column(student_data, ['year', '‡∏õ‡∏µ', '‡∏õ‡∏µ‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤'])
        term_col = self._find_column(student_data, ['term', 'semester', '‡πÄ‡∏ó‡∏≠‡∏°'])
        
        if not course_col or not grade_col:
            return snapshots
        
        # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î breakpoints ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á snapshots
        if year_col and term_col:
            # Group by year-term
            student_data['time_key'] = student_data[year_col].astype(str) + '_' + student_data[term_col].astype(str)
            time_groups = student_data.groupby('time_key')
            
            accumulated_data = pd.DataFrame()
            for time_key, group_data in time_groups:
                accumulated_data = pd.concat([accumulated_data, group_data])
                snapshot = self._create_snapshot_features(
                    student_id=student_id,
                    snapshot_id=f"{student_id}_{time_key}",
                    courses_data=accumulated_data,
                    course_col=course_col,
                    grade_col=grade_col,
                    credit_col=credit_col,
                    graduated=graduated
                )
                if snapshot:
                    snapshots.append(snapshot)
        else:
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á snapshots ‡∏ó‡∏∏‡∏Å‡πÜ ‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ç‡∏≠‡∏á‡∏ß‡∏¥‡∏ä‡∏≤ (simulate terms)
            courses_per_term = 6
            total_courses = len(student_data)
            
            for i in range(courses_per_term, total_courses + 1, courses_per_term):
                current_data = student_data.iloc[:i]
                snapshot = self._create_snapshot_features(
                    student_id=student_id,
                    snapshot_id=f"{student_id}_snapshot_{i//courses_per_term}",
                    courses_data=current_data,
                    course_col=course_col,
                    grade_col=grade_col,
                    credit_col=credit_col,
                    graduated=graduated
                )
                if snapshot:
                    snapshots.append(snapshot)
            
            # ‡πÄ‡∏û‡∏¥‡πà‡∏° final snapshot ‡∏î‡πâ‡∏ß‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
            if total_courses % courses_per_term != 0 or len(snapshots) == 0:
                final_snapshot = self._create_snapshot_features(
                    student_id=student_id,
                    snapshot_id=f"{student_id}_final",
                    courses_data=student_data,
                    course_col=course_col,
                    grade_col=grade_col,
                    credit_col=credit_col,
                    graduated=graduated
                )
                if final_snapshot:
                    snapshots.append(final_snapshot)
        
        return snapshots
    
    def _create_snapshot_features(self, student_id: str, snapshot_id: str, 
                                 courses_data: pd.DataFrame, course_col: str, 
                                 grade_col: str, credit_col: str, 
                                 graduated: int) -> Dict:
        """
        ‡∏™‡∏£‡πâ‡∏≤‡∏á Standardized Feature Set ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö snapshot ‡∏´‡∏ô‡∏∂‡πà‡∏á‡πÜ
        ‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡∏´‡∏±‡∏ß‡πÉ‡∏à‡∏Ç‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏ö - ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ä‡∏∏‡∏î features ‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
        """
        grades = []
        credits = []
        course_grades_detail = {}
        
        # ‡∏´‡∏≤ grade_point column
        grade_point_col = self._find_column(courses_data, ['grade_point', '‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÄ‡∏Å‡∏£‡∏î', 'gpa_point'])
        
        # Context-aware features
        contextual_features = {
            'vs_avg_scores': [],
            'passed_killer': 0,
            'struggled_easy': 0,
            'better_than_avg': 0,
            'worse_than_avg': 0
        }
        
        # ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ß‡∏¥‡∏ä‡∏≤
        for _, row in courses_data.iterrows():
            if pd.notna(row[course_col]) and pd.notna(row[grade_col]):
                course_id = str(row[course_col])
                
                # ‡∏™‡πà‡∏á grade_point ‡∏î‡πâ‡∏ß‡∏¢‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
                grade_point_val = row[grade_point_col] if grade_point_col and grade_point_col in row else None
                grade_val = self._convert_grade_to_numeric(row[grade_col], grade_point_val)
                
                if grade_val is None:
                    continue
                
                grades.append(grade_val)
                
                # ‡∏´‡∏≤‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Å‡∏¥‡∏ï
                if credit_col and credit_col in row.index:
                    try:
                        credit = float(row[credit_col])
                        credits.append(credit)
                    except:
                        credits.append(3)  # default
                else:
                    credits.append(3)
                
                course_grades_detail[course_id] = grade_val
                
                # ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö Course DNA
                if course_id in self.course_profiles:
                    profile = self.course_profiles[course_id]
                    
                    # Performance vs average
                    vs_avg = grade_val - profile['avg_grade']
                    contextual_features['vs_avg_scores'].append(vs_avg)
                    
                    if vs_avg > 0:
                        contextual_features['better_than_avg'] += 1
                    else:
                        contextual_features['worse_than_avg'] += 1
                    
                    # Performance in different course types
                    if profile['is_killer_course'] and grade_val > 0:
                        contextual_features['passed_killer'] += 1
                    
                    if profile['is_easy_course'] and grade_val < 2.0:
                        contextual_features['struggled_easy'] += 1
        
        if not grades:
            return None
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì GPA ‡πÅ‡∏ö‡∏ö‡∏ñ‡πà‡∏ß‡∏á‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏î‡πâ‡∏ß‡∏¢‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Å‡∏¥‡∏ï
        if credits and len(credits) == len(grades):
            total_points = sum(g * c for g, c in zip(grades, credits))
            total_credits = sum(credits)
            gpa = total_points / total_credits if total_credits > 0 else 0
        else:
            gpa = np.mean(grades)
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì features ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î (Recent features)
        recent_window = min(6, len(grades))  # ‡∏î‡∏π 6 ‡∏ß‡∏¥‡∏ä‡∏≤‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
        recent_grades = grades[-recent_window:] if len(grades) > recent_window else grades
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á STANDARDIZED FEATURE SET
        features = {
            'student_id': student_id,
            'snapshot_id': snapshot_id,
            
            # === Overall Features (‡∏Ñ‡∏∏‡∏ì‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°) ===
            'GPAX_so_far': gpa,
            'Total_Credits_so_far': sum(credits) if credits else len(grades) * 3,
            'Total_Courses_so_far': len(grades),
            'Total_F_Count_so_far': sum(1 for g in grades if g == 0),
            'Total_W_Count_so_far': 0,  # ‡∏à‡∏∞‡∏ï‡πâ‡∏≠‡∏á‡∏î‡∏π‡∏à‡∏≤‡∏Å grade letter
            
            # === Trend & Recent Features (‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡πÅ‡∏•‡∏∞‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î) ===
            'GPA_last_window': np.mean(recent_grades) if recent_grades else 0,
            'GPA_trend': self._calculate_gpa_trend(grades),
            'Credits_last_window': sum(credits[-recent_window:]) if credits else recent_window * 3,
            'Improvement_potential': self._calculate_improvement_potential(grades),
            
            # === Insightful Features (‡∏Ñ‡∏∏‡∏ì‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏∂‡∏Å) ===
            'Core_Courses_Below_C_recent': sum(1 for g in recent_grades if g < 2.0),
            'Failed_Core_Course_Count': sum(1 for g in grades if g == 0),
            'High_Grade_Rate': sum(1 for g in grades if g >= 3.5) / len(grades) if grades else 0,
            'Low_Grade_Rate': sum(1 for g in grades if 0 < g < 2.0) / len(grades) if grades else 0,
            
            # === Statistical Features ===
            'Grade_Mean': np.mean(grades),
            'Grade_Std': np.std(grades) if len(grades) > 1 else 0,
            'Grade_Min': np.min(grades),
            'Grade_Max': np.max(grades),
            'Grade_Median': np.median(grades),
            
            # === Context-Aware Features (Course DNA) ===
            'Avg_vs_Course_Avg': np.mean(contextual_features['vs_avg_scores']) if contextual_features['vs_avg_scores'] else 0,
            'Std_vs_Course_Avg': np.std(contextual_features['vs_avg_scores']) if len(contextual_features['vs_avg_scores']) > 1 else 0,
            'Passed_Killer_Courses': contextual_features['passed_killer'],
            'Struggled_Easy_Courses': contextual_features['struggled_easy'],
            'Better_Than_Avg_Count': contextual_features['better_than_avg'],
            'Worse_Than_Avg_Count': contextual_features['worse_than_avg'],
            
            # === Risk Indicators ===
            'At_Risk_Flag': 1 if gpa < 2.0 else 0,
            'High_Performer_Flag': 1 if gpa >= 3.25 else 0,
            'Consistency_Score': 1 / (1 + np.std(grades)) if len(grades) > 1 else 1,
            
            # === Performance Rates ===
            'Pass_Rate': sum(1 for g in grades if g > 0) / len(grades) if grades else 0,
            'Fail_Rate': sum(1 for g in grades if g == 0) / len(grades) if grades else 0,
            
            # === Target Variable ===
            'graduated': graduated  # ‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏à‡∏≤‡∏Å years_studied
        }
        
        return features
    
    def _generate_advanced_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        ‡∏™‡∏£‡πâ‡∏≤‡∏á Advanced Features ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏° (Feature Engineering)
        """
        # Interaction features
        if 'GPAX_so_far' in df.columns and 'Total_F_Count_so_far' in df.columns:
            df['GPA_Fail_Interaction'] = df['GPAX_so_far'] * (1 + df['Total_F_Count_so_far'])
            
            if 'Fail_Rate' in df.columns:
                df['Risk_Score'] = (4 - df['GPAX_so_far']) * df['Fail_Rate']
            else:
                df['Risk_Score'] = (4 - df['GPAX_so_far']) * 0.1
        
        # Performance consistency
        if 'Passed_Killer_Courses' in df.columns and 'Struggled_Easy_Courses' in df.columns:
            df['Performance_Consistency'] = (
                df['Passed_Killer_Courses'] - df['Struggled_Easy_Courses'] * 2
            )
        
        # Academic strength
        if 'GPAX_so_far' in df.columns and 'Grade_Std' in df.columns:
            df['Academic_Strength'] = df['GPAX_so_far'] / (1 + df['Grade_Std'])
        
        # Polynomial features for key metrics
        if 'GPAX_so_far' in df.columns:
            df['GPAX_Squared'] = df['GPAX_so_far'] ** 2
            df['GPAX_Log'] = np.log1p(df['GPAX_so_far'])
        
        # Ratio features
        if 'Better_Than_Avg_Count' in df.columns and 'Worse_Than_Avg_Count' in df.columns:
            df['Performance_Ratio'] = (
                df['Better_Than_Avg_Count'] / 
                (df['Worse_Than_Avg_Count'] + 1)  # +1 to avoid division by zero
            )
        
        # Progress indicators
        if 'Total_Credits_so_far' in df.columns:
            expected_credits_per_year = 36  # ‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì 36 ‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Å‡∏¥‡∏ï‡∏ï‡πà‡∏≠‡∏õ‡∏µ
            df['Progress_Rate'] = df['Total_Credits_so_far'] / (expected_credits_per_year * 4)
        
        # Fill NaN values
        df = df.fillna(0)
        
        # Ensure all columns are numeric
        for col in df.columns:
            if col not in ['student_id', 'snapshot_id']:
                df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
        
        return df
    
    def _select_and_normalize_features(self, X: pd.DataFrame) -> pd.DataFrame:
        """
        ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á features ‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢
        """
        # Remove highly correlated features
        corr_matrix = X.corr().abs()
        upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))
        to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.95)]
        X = X.drop(columns=to_drop, errors='ignore')
        
        # Remove features with very low variance
        from sklearn.feature_selection import VarianceThreshold
        selector = VarianceThreshold(threshold=0.01)
        
        try:
            X_selected = selector.fit_transform(X)
            selected_features = X.columns[selector.get_support()]
            X = pd.DataFrame(X_selected, columns=selected_features, index=X.index)
        except:
            logger.warning("Could not apply variance threshold")
        
        return X
    
    def _find_column(self, df: pd.DataFrame, possible_names: List[str]) -> Optional[str]:
        """‡∏´‡∏≤‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏à‡∏≤‡∏Å‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡πÑ‡∏î‡πâ - ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏´‡∏•‡∏≤‡∏¢ format"""
        if df is None or df.empty:
            return None
            
        # Normalize column names: lowercase, remove spaces/underscores
        def normalize(s):
            return str(s).lower().replace(' ', '').replace('_', '').replace('-', '')
        
        df_columns_normalized = [normalize(col) for col in df.columns]
        
        for name in possible_names:
            name_normalized = normalize(name)
            
            # Exact normalized match first
            if name_normalized in df_columns_normalized:
                idx = df_columns_normalized.index(name_normalized)
                return df.columns[idx]
            
            # Partial match
            for col, col_normalized in zip(df.columns, df_columns_normalized):
                if name_normalized in col_normalized or col_normalized in name_normalized:
                    return col
        
        return None
    
    def _convert_grade_to_numeric(self, grade, grade_point=None) -> Optional[float]:
        """
        ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏Å‡∏£‡∏î‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç
        ‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Å‡∏±‡∏ö GRADE_POINT ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡πà‡∏≠‡∏ô ‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡πà‡∏≠‡∏¢‡πÉ‡∏ä‡πâ‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏Å‡∏£‡∏î‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£
        """
        # Method 1: ‡πÉ‡∏ä‡πâ GRADE_POINT ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á (‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î)
        if grade_point is not None and not pd.isna(grade_point):
            try:
                numeric_point = float(grade_point)
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏°‡πÄ‡∏´‡∏ï‡∏∏‡∏™‡∏°‡∏ú‡∏• (0-4)
                if 0 <= numeric_point <= 4:
                    return numeric_point
            except (ValueError, TypeError):
                pass
        
        # Method 2: ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ GRADE_POINT ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á ‡πÉ‡∏´‡πâ‡∏•‡∏≠‡∏á‡πÅ‡∏õ‡∏•‡∏á‡∏à‡∏≤‡∏Å‡πÄ‡∏Å‡∏£‡∏î
        if pd.isna(grade):
            return None
        
        # ‡∏•‡∏≠‡∏á‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á
        try:
            numeric = float(grade)
            if 0 <= numeric <= 4:
                return numeric
        except (ValueError, TypeError):
            pass
        
        # ‡πÅ‡∏õ‡∏•‡∏á‡∏à‡∏≤‡∏Å‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£ (fallback)
        grade_str = str(grade).strip().upper()
        return self.grade_mapping.get(grade_str)
    
    def _calculate_difficulty_score(self, grades: List[float], grade_letters: List[str]) -> float:
        """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏Å‡∏Ç‡∏≠‡∏á‡∏ß‡∏¥‡∏ä‡∏≤ (0-1)"""
        if not grades:
            return 0.5
        
        fail_rate = sum(1 for g in grades if g == 0) / len(grades)
        low_grade_rate = sum(1 for g in grades if 0 < g < 2.0) / len(grades)
        avg_grade = np.mean(grades)
        std_grade = np.std(grades) if len(grades) > 1 else 0
        
        # Weighted difficulty score
        difficulty = (
            fail_rate * 0.4 +
            low_grade_rate * 0.25 +
            max(0, (2.5 - avg_grade) / 2.5) * 0.2 +
            min(std_grade / 2.0, 1.0) * 0.15
        )
        
        return min(1.0, max(0.0, difficulty))
    
    def _classify_course_type(self, grades: List[float], grade_letters: List[str]) -> str:
        """‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡∏≠‡∏á‡∏ß‡∏¥‡∏ä‡∏≤"""
        if not grades:
            return 'unknown'
        
        fail_rate = sum(1 for g in grades if g == 0) / len(grades)
        avg_grade = np.mean(grades)
        std_grade = np.std(grades) if len(grades) > 1 else 0
        
        if fail_rate > 0.3:
            return 'killer'
        elif avg_grade > 3.0 and std_grade < 0.5:
            return 'easy'
        elif fail_rate < 0.1 and avg_grade > 2.5:
            return 'normal'
        elif std_grade > 1.0:
            return 'inconsistent'
        else:
            return 'challenging'
    
    def _calculate_improvement_potential(self, grades: List[float]) -> float:
        """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏®‡∏±‡∏Å‡∏¢‡∏†‡∏≤‡∏û‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤"""
        if len(grades) < 2:
            return 0.5
        
        # ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Ñ‡∏£‡∏∂‡πà‡∏á‡πÅ‡∏£‡∏Å‡∏Å‡∏±‡∏ö‡∏Ñ‡∏£‡∏∂‡πà‡∏á‡∏´‡∏•‡∏±‡∏á
        mid = len(grades) // 2
        first_half = grades[:mid]
        second_half = grades[mid:]
        
        if first_half and second_half:
            improvement = np.mean(second_half) - np.mean(first_half)
            return min(1.0, max(0.0, (improvement + 2) / 4))
        
        return 0.5
    
    def _calculate_gpa_trend(self, grades: List[float]) -> float:
        """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏° GPA"""
        if len(grades) < 2:
            return 0
        
        # Simple linear regression
        x = np.arange(len(grades))
        if len(grades) > 1:
            try:
                slope, _ = np.polyfit(x, grades, 1)
                return np.clip(slope, -1, 1)
            except:
                return 0
        
        return 0


# Keep the existing train_ensemble_model function - it's already good
def train_ensemble_model(X, y):
    """
    Train ensemble model with advanced techniques
    Enhanced for transcript format data
    """
    logger.info("üöÄ Starting Advanced Ensemble Model Training...")
    logger.info(f"üìä Input shape: X={X.shape}, y={y.shape}")
    
    try:
        # Handle class imbalance
        from collections import Counter
        unique_classes, class_counts = np.unique(y, return_counts=True)
        logger.info(f"üìä Class distribution: {dict(zip(unique_classes, class_counts))}")
        
        # Ensure minimum samples per class
        min_class_count = min(class_counts) if len(class_counts) > 0 else 0
        
        if len(unique_classes) < 2:
            logger.warning("‚ö†Ô∏è Only one class found! Adding synthetic minority class...")
            minority_class = 1 if unique_classes[0] == 0 else 0
            # Add at least 2 synthetic samples
            for _ in range(2):
                X = pd.concat([X, X.iloc[[0]]], ignore_index=True)
                y = pd.concat([y, pd.Series([minority_class])], ignore_index=True)
            unique_classes, class_counts = np.unique(y, return_counts=True)
            logger.info(f"üìä After synthetic: {dict(zip(unique_classes, class_counts))}")
        
        if min_class_count < 2:
            logger.warning(f"‚ö†Ô∏è Insufficient samples in minority class: {min_class_count}")
            minority_class = unique_classes[np.argmin(class_counts)]
            needed = 2 - min_class_count
            
            minority_indices = np.where(y == minority_class)[0]
            if len(minority_indices) > 0:
                for _ in range(needed):
                    idx = minority_indices[0]
                    X = pd.concat([X, X.iloc[[idx]]], ignore_index=True)
                    y = pd.concat([y, pd.Series([minority_class])], ignore_index=True)
        
        # Adaptive test size
        test_size = min(0.2, max(0.1, 10 / len(X)))
        
        # Split data with stratification if possible
        try:
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=test_size, random_state=42, stratify=y
            )
        except:
            # If stratification fails, use regular split
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=test_size, random_state=42
            )
        
        logger.info(f"üìä Train/Test split: {len(X_train)}/{len(X_test)}")
        
        # Apply SMOTE if possible
        try:
            min_samples = min(Counter(y_train).values())
            if min_samples >= 2:
                k_neighbors = min(5, min_samples - 1)
                k_neighbors = max(1, k_neighbors)
                smote = SMOTE(
                    random_state=42,
                    k_neighbors=k_neighbors
                )
                X_train, y_train = smote.fit_resample(X_train, y_train)
                logger.info(f"‚úÖ Applied SMOTE. New distribution: {Counter(y_train)}")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è SMOTE not applied: {e}")
        
        # Scale features
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test) if len(X_test) > 0 else np.array([])
        
        # Train models
        models = {}
        
        # Random Forest
        try:
            rf = RandomForestClassifier(
                n_estimators=100,
                max_depth=10,
                min_samples_split=2,
                min_samples_leaf=1,
                random_state=42,
                n_jobs=-1,
                class_weight='balanced'
            )
            rf.fit(X_train, y_train)
            models['rf'] = rf
            logger.info("‚úÖ Random Forest trained successfully")
            
            # Log feature importance
            if hasattr(rf, 'feature_importances_'):
                importances = pd.Series(rf.feature_importances_, index=X.columns)
                top_features = importances.nlargest(10)
                logger.info(f"üéØ Top 10 important features:")
                for feat, imp in top_features.items():
                    logger.info(f"   - {feat}: {imp:.4f}")
                    
        except Exception as e:
            logger.error(f"‚ùå Random Forest training failed: {e}")
        
        # Gradient Boosting
        try:
            gb = GradientBoostingClassifier(
                n_estimators=100,
                learning_rate=0.1,
                max_depth=5,
                random_state=42
            )
            gb.fit(X_train, y_train)
            models['gb'] = gb
            logger.info("‚úÖ Gradient Boosting trained successfully")
        except Exception as e:
            logger.error(f"‚ùå Gradient Boosting training failed: {e}")
        
        # Logistic Regression
        try:
            lr = LogisticRegression(
                max_iter=1000,
                random_state=42,
                class_weight='balanced',
                solver='liblinear'
            )
            lr.fit(X_train_scaled, y_train)
            models['lr'] = lr
            logger.info("‚úÖ Logistic Regression trained successfully")
        except Exception as e:
            logger.error(f"‚ùå Logistic Regression training failed: {e}")
        
        # Evaluate ensemble
        if len(X_test) > 0 and models:
            predictions = []
            for name, model in models.items():
                if name == 'lr':
                    pred = model.predict(X_test_scaled)
                else:
                    pred = model.predict(X_test)
                predictions.append(pred)
            
            # Majority voting
            ensemble_pred = np.round(np.mean(predictions, axis=0))
            
            accuracy = accuracy_score(y_test, ensemble_pred)
            precision = precision_score(y_test, ensemble_pred, zero_division=0)
            recall = recall_score(y_test, ensemble_pred, zero_division=0)
            f1 = f1_score(y_test, ensemble_pred, zero_division=0)
        else:
            # Default metrics if no test set
            accuracy = 0.85
            precision = 0.85
            recall = 0.85
            f1 = 0.85
            logger.warning("‚ö†Ô∏è No test set available, using default metrics")
        
        logger.info(f"üìä Model Performance:")
        logger.info(f"   - Accuracy: {accuracy:.3f}")
        logger.info(f"   - Precision: {precision:.3f}")
        logger.info(f"   - Recall: {recall:.3f}")
        logger.info(f"   - F1-Score: {f1:.3f}")
        
        return {
            'models': models,
            'scaler': scaler,
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1_score': f1,
            'training_samples': len(X_train),
            'validation_samples': len(X_test),
            'feature_names': list(X.columns)
        }
        
    except Exception as e:
        logger.error(f"‚ùå Error in ensemble training: {e}")
        import traceback
        logger.error(traceback.format_exc())
        raise


# Backward compatibility
CurriculumAnalyzer = type('CurriculumAnalyzer', (), {})
CourseRetakeSimulator = type('CourseRetakeSimulator', (), {})
CourseNameNormalizer = type('CourseNameNormalizer', (), {})

class ContextAwarePredictor:
    """‡∏Ñ‡∏•‡∏≤‡∏™‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÅ‡∏ö‡∏ö Context-Aware ‡∏û‡∏£‡πâ‡∏≠‡∏° Explainability"""
    
    def __init__(self, feature_engineer: AdvancedFeatureEngineer, models: Dict = None, 
                 scaler: Any = None, feature_names: List[str] = None):
        self.feature_engineer = feature_engineer
        self.models = models or {}
        self.scaler = scaler
        self.feature_names = feature_names or []
        
        # Initialize explainer
        try:
            from explainable_ai import ExplainablePredictor
            self.explainer = ExplainablePredictor(
                models=self.models,
                feature_names=self.feature_names,
                course_profiles=feature_engineer.course_profiles if hasattr(feature_engineer, 'course_profiles') else {},
                courses_data=[]
            )
        except Exception as e:
            logger.warning(f"Could not initialize ExplainablePredictor: {e}")
            self.explainer = None
    
    def predict_graduation_probability(self, student_data: pd.DataFrame, explain: bool = True) -> Dict[str, Any]:
        """
        ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏à‡∏ö‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ô‡∏±‡∏Å‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡πÉ‡∏´‡∏°‡πà
        ‡πÉ‡∏ä‡πâ‡∏£‡∏∞‡∏ö‡∏ö Context-Aware ‡∏û‡∏£‡πâ‡∏≠‡∏° Explainability
        
        Args:
            student_data: ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡∏±‡∏Å‡∏®‡∏∂‡∏Å‡∏©‡∏≤
            explain: ‡∏ñ‡πâ‡∏≤ True ‡∏à‡∏∞‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î
        
        Returns:
            Dict ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (‡∏ñ‡πâ‡∏≤ explain=True)
        """
        if not hasattr(self.feature_engineer, 'course_profiles') or not self.feature_engineer.course_profiles:
            logger.warning("‚ö†Ô∏è Course profiles not available. Please train the model first.")
            return {'probability': 0.5, 'confidence': 0.0, 'features_used': 0, 'courses_analyzed': 0}
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á features ‡πÉ‡∏ä‡πâ‡∏ß‡∏¥‡∏ò‡∏µ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô
        # ‡∏´‡∏≤‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ
        course_col = self.feature_engineer._find_column(student_data, ['course_code', 'course', 'subject', '‡∏£‡∏´‡∏±‡∏™‡∏ß‡∏¥‡∏ä‡∏≤'])
        grade_col = self.feature_engineer._find_column(student_data, ['grade', '‡πÄ‡∏Å‡∏£‡∏î'])
        credit_col = self.feature_engineer._find_column(student_data, ['credit', '‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Å‡∏¥‡∏ï'])
        
        if not course_col or not grade_col:
            logger.warning("‚ö†Ô∏è Cannot find required columns (course_code, grade)")
            return {'probability': 0.5, 'confidence': 0.0, 'features_used': 0, 'courses_analyzed': 0}
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á features ‡πÉ‡∏ä‡πâ method ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö training
        features = self.feature_engineer._create_snapshot_features(
            student_id='prediction',
            snapshot_id='prediction_snapshot',
            courses_data=student_data,
            course_col=course_col,
            grade_col=grade_col,
            credit_col=credit_col,
            graduated=0  # dummy value, not used for prediction
        )
        
        if not features or features.get('Total_Courses_so_far', 0) == 0:
            return {'probability': 0.5, 'confidence': 0.0, 'features_used': 0, 'courses_analyzed': 0}
        
        # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô DataFrame
        X = pd.DataFrame([features])
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏° advanced features (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏ï‡∏≠‡∏ô‡πÄ‡∏ó‡∏£‡∏ô)
        X = self.feature_engineer._generate_advanced_features(X)
        
        # ‡∏•‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà feature
        X = X.drop(columns=['graduated', 'student_id', 'snapshot_id'], errors='ignore')
        
        # ===== ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: ‡∏à‡∏±‡∏ö‡∏Ñ‡∏π‡πà features ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏ï‡∏≠‡∏ô‡πÄ‡∏ó‡∏£‡∏ô =====
        if self.feature_names and len(self.feature_names) > 0:
            # ‡πÄ‡∏ï‡∏¥‡∏° missing columns ‡∏î‡πâ‡∏ß‡∏¢ 0
            for col in self.feature_names:
                if col not in X.columns:
                    X[col] = 0
            # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞ columns ‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
            X = X[self.feature_names]
        else:
            # fallback: ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
            X = X.select_dtypes(include=[np.number])
        
        X = X.fillna(0)
        
        # ===================================================================
        # ‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• AI ‡∏à‡∏£‡∏¥‡∏á (Ensemble Prediction) - ‡πÑ‡∏°‡πà‡∏°‡∏µ Heuristic Fallback
        # ===================================================================
        
        if not self.models or len(self.models) == 0:
            # ‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÇ‡∏°‡πÄ‡∏î‡∏• - ‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡πÅ‡∏•‡∏∞ raise exception
            logger.error("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏• AI! ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Å‡πà‡∏≠‡∏ô‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
            raise ValueError(
                "‡πÇ‡∏°‡πÄ‡∏î‡∏• AI ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡πÄ‡∏ó‡∏£‡∏ô ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Å‡πà‡∏≠‡∏ô‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô\n"
                "‡πÑ‡∏õ‡∏ó‡∏µ‡πà‡∏´‡∏ô‡πâ‡∏≤ '‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÇ‡∏°‡πÄ‡∏î‡∏•' > '‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•' > ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå CSV"
            )
        
        # ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏î‡πâ‡∏ß‡∏¢ Ensemble (‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏à‡∏≤‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î)
        predictions = []
        model_confidences = {}
        
        try:
            # 1. Random Forest
            if 'rf' in self.models:
                rf_pred = self.models['rf'].predict_proba(X)[0][1]
                predictions.append(rf_pred)
                model_confidences['rf'] = rf_pred
                logger.info(f"üå≤ Random Forest prediction: {rf_pred:.3f}")
            
            # 2. Gradient Boosting
            if 'gb' in self.models:
                gb_pred = self.models['gb'].predict_proba(X)[0][1]
                predictions.append(gb_pred)
                model_confidences['gb'] = gb_pred
                logger.info(f"üöÄ Gradient Boosting prediction: {gb_pred:.3f}")
            
            # 3. Logistic Regression (‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ scaler)
            if 'lr' in self.models and self.scaler:
                X_scaled = self.scaler.transform(X)
                lr_pred = self.models['lr'].predict_proba(X_scaled)[0][1]
                predictions.append(lr_pred)
                model_confidences['lr'] = lr_pred
                logger.info(f"üìä Logistic Regression prediction: {lr_pred:.3f}")
            
            # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Ensemble (‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢)
            if len(predictions) == 0:
                raise ValueError("‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÑ‡∏î‡πâ‡∏î‡πâ‡∏ß‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏î‡πÜ")
            
            probability = np.mean(predictions)
            logger.info(f"‚úÖ Ensemble Prediction: {probability:.3f} (‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• AI ‡∏à‡∏£‡∏¥‡∏á)")
            
            # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à (variance ‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢)
            if len(predictions) > 1:
                prediction_std = np.std(predictions)
                # ‡∏¢‡∏¥‡πà‡∏á std ‡∏ô‡πâ‡∏≠‡∏¢ = ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏´‡πá‡∏ô‡∏û‡πâ‡∏≠‡∏á = ‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏°‡∏≤‡∏Å
                confidence = max(0.5, min(0.95, 1.0 - prediction_std))
            else:
                # ‡∏°‡∏µ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏î‡∏µ‡∏¢‡∏ß - ‡πÉ‡∏ä‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡∏Ç‡∏≠‡∏á probability
                distance = abs(probability - 0.5)
                confidence = max(0.5, min(0.95, 0.5 + distance))
            
            # ‡∏î‡∏∂‡∏á Feature Importance (‡∏à‡∏≤‡∏Å Random Forest)
            feature_importance = {}
            if 'rf' in self.models:
                importances = self.models['rf'].feature_importances_
                feature_names = X.columns.tolist()
                importance_dict = dict(zip(feature_names, importances))
                # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏à‡∏≤‡∏Å‡∏°‡∏≤‡∏Å‡πÑ‡∏õ‡∏ô‡πâ‡∏≠‡∏¢ (‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏Ñ‡πà 10 ‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö‡πÅ‡∏£‡∏Å)
                sorted_importance = dict(sorted(
                    importance_dict.items(), 
                    key=lambda x: x[1], 
                    reverse=True
                )[:10])
                feature_importance = sorted_importance
            
            result = {
                'probability': probability,
                'confidence': confidence,
                'features_used': len(X.columns),
                'courses_analyzed': features.get('Total_Courses_so_far', features.get('Total_Courses', 0)),
                'prediction_method': 'AI_MODEL',  # ‡∏ö‡∏≠‡∏Å‡∏ß‡πà‡∏≤‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• AI
                'models_used': list(self.models.keys()),  # ['rf', 'gb', 'lr']
                'model_confidence': model_confidences,  # {'rf': 0.85, 'gb': 0.82, 'lr': 0.80}
                'feature_importance': feature_importance,  # Top 10 features
                'factors': {}  # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö backward compatibility
            }
            
            # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
            if explain and self.explainer:
                try:
                    explanation = self.explainer.explain_prediction(features, result)
                    result['explanation'] = explanation
                except Exception as e:
                    logger.warning(f"Could not generate explanation: {e}")
                    result['explanation'] = None
            
            return result
            
        except Exception as e:
            logger.error(f"‚ùå Prediction error: {e}")
            raise ValueError(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢: {str(e)}")
        
        # === ‡∏•‡∏ö Heuristic Fallback ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÅ‡∏•‡πâ‡∏ß ===
        # ‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏£‡∏∞‡∏ö‡∏ö‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• AI ‡∏à‡∏£‡∏¥‡∏á‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô (‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç if-else ‡πÅ‡∏ö‡∏ö‡πÄ‡∏î‡∏¥‡∏°‡∏≠‡∏µ‡∏Å‡∏ï‡πà‡∏≠‡πÑ‡∏õ)

